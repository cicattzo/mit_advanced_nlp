{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Ha3_Trees.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cicattzo/mit_advanced_nlp/blob/main/Ha3_Trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY7OK7jKHN4C"
      },
      "source": [
        "## **Introduction**\n",
        "Welcome to **Homework 3 - Trees**! In this homework, we will practice *parsing* on sentences from a semantic parsing corpus.  \n",
        "\n",
        "The data is obtained from this [paper](https://arxiv.org/pdf/1810.07942.pdf) (see Figure 1). As you can see from the figure, the purpose of this task is to understand what are the users *intents* from a query in plain text.  \n",
        "\n",
        "The end goal is that given sentence to decode a binary **tree structure** with *semantic tags* as *nodes*. For example:\n",
        "\n",
        "> whats there to do this weekend -> [<font color='00b8d4'>IN:GET_EVENT</font> whats there to do [<font color='00b8d4'>SL:DATE_TIME</font> this weekend]]  \n",
        "\n",
        "Note that the brackets [<font color='00b8d4'>LABEL</font> a substring of the text] indicates that this span is a sub-tree and <font color='00b8d4'>LABEL</font>  is the semantic label of the root of the sub-tree. You might read more about bracket representation in this [tutorial](https://www.tutorialspoint.com/binary-tree-to-string-with-brackets-in-cplusplus). \n",
        "\n",
        "1. In **Part A**, we formulate this problem as a simple classification problem --- the input to the classifier will be `(text, span)` and the output will be the semantic `label` of that span. `span`  is represented by two integer `(i,j)` which are the start and the end locations of the span.\n",
        "\n",
        "2. In **Part B**, we will implement a **CKY**-style decoding algorithm to decode the final tree based on the classifier we trained in Part A.\n",
        "\n",
        "We did pre-processing to enable CKY-style decoding for you. This includes binarization of the trees and handling of unary rules. (see the [code](https://github.mit.edu/tianxing/mit_6864_hw3_202003)).  \n",
        "\n",
        "Let's start by loading some dependencies and downloading the data as usual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Nsi5pHEHXIN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9821225-97a6-4d36-814f-61108aaca8e6"
      },
      "source": [
        "%%bash\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
        "rm -rf hw3\n",
        "git clone https://github.com/mit-6864/hw3.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'hw3'...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIOkqXIoHN4H"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/hw3/trees/\")\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from torch import cuda\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from span_tree import *\n",
        "seed = 0\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "if cuda.is_available():\n",
        "  device = 'cuda'\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "else:\n",
        "  print('WARNING: you are running this assignment on a cpu!')\n",
        "  device = 'cpu'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mQzMXTeHN4M"
      },
      "source": [
        "## **Agenda**\n",
        "\n",
        "We apply a model that learns the parsing structures in 4 steps.\n",
        "\n",
        "1. Enumerate all possible spans of a sentence\n",
        "2. Generating word and span embeddings\n",
        "3. Learning span label classifications\n",
        "4. Decoding a tree structure using the classification distributions of spans\n",
        "\n",
        "We go through this process step by step through the homework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnUOkaRgqRbW"
      },
      "source": [
        "## **PARTA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvYHEHBJwuk4"
      },
      "source": [
        "### **Data Processing**\n",
        "\n",
        "The very first step of the project is to load the corpus, building the **vocabulary**, **span label set**, and **span indices**. \n",
        "\n",
        "We first need to enumerate every node of a tree with a Depth First Search (DFS)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAauBjH1d9Up"
      },
      "source": [
        "def tree_dfs(node, span_list, label_dict, mode):\n",
        "    \"\"\"\n",
        "    The base function for the recursion:\n",
        "      node: current root while traversing the tree\n",
        "      span_list: keep tracks of the spans an their label encodings in the tree e.g [[(0,1), 1], [(0,6),45] ...] \n",
        "      label_dict: mapping from label to their encodings e.g {\"UNK\":0, \"Token\":1,\"None\":2, ... }\n",
        "      mode: \"train\" or \"eval\"\n",
        "    \"\"\"\n",
        "  \n",
        "    if len(node.children) == 0:\n",
        "        assert(type(node) == Token)\n",
        "        cur_span = (node.index, node.index + 1)\n",
        "        cur_label = label_dict['Token']\n",
        "        span_list.append([cur_span, cur_label])\n",
        "        return span_list, label_dict\n",
        "        \n",
        "    cur_span = node.get_token_span()\n",
        "    cur_label = node.label\n",
        "    if node.label in label_dict:\n",
        "        cur_label = label_dict[node.label]\n",
        "    elif mode == 'train': # we are constructing the label dictionary\n",
        "        cur_label = len(label_dict)\n",
        "        label_dict[node.label] = cur_label\n",
        "    else:\n",
        "        cur_label = label_dict['UNK']\n",
        "    span_list.append([cur_span, cur_label])\n",
        "    \n",
        "    if len(node.children) > 1: #if only has one child, we will ignore the Token label, otherwise the token span would have two conflicting labels\n",
        "        for child in node.children:\n",
        "            # --------- Your code (hint: only need one single line) --------- #\n",
        "            tree_dfs(child, span_list, label_dict, mode)\n",
        "            # --------- Your code ends --------- # \n",
        "    return span_list, label_dict"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42LFAdiqeCCE"
      },
      "source": [
        "Now, we go through the corpus and construct the **vocab dictionary** and the **label dictionary**. Note that we just adding new words and labels to the dictionaries while building the training set. Unseen words or labels in validation and test set are marked as unknown (UNK)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHZ4qUgoHN4N"
      },
      "source": [
        "def process_line(line, vocab_dict, label_dict, mode):\n",
        "    '''\n",
        "    Processing a line in the corpus.\n",
        "    line format: Sentence \\t Sentence_Tree \\n\n",
        "    \n",
        "    Example:\n",
        "        'what is the shortest way home\\t\n",
        "        [IN:GET_DIRECTIONS what [SUB is [SUB the [SUB shortest [SUB way [SL:DESTINATION home ] ] ] ] ] ]\\n'\n",
        "    \n",
        "    Inputs:\n",
        "    vocab_dict: vocab dictionary {word: word_index, ...}\n",
        "    labels_dict: label dictionary {label: label_index, ...}\n",
        "    '''\n",
        "    s, s_tree = line.strip().split('\\t')\n",
        "    words = s.split(' ')\n",
        "    word_ids = []\n",
        "    for word in words:\n",
        "        if word in vocab_dict:\n",
        "            word_ids.append(vocab_dict[word])\n",
        "        elif mode == 'train':\n",
        "            word_ids.append(len(vocab_dict))\n",
        "            vocab_dict[word] = len(vocab_dict)\n",
        "        else:\n",
        "            word_ids.append(vocab_dict['UNK'])\n",
        "    \n",
        "    tree = Tree(s_tree)\n",
        "    span_list = []\n",
        "    span_list, label_dict = tree_dfs(tree.root.children[0], span_list, label_dict, mode)\n",
        "    return word_ids, span_list, vocab_dict, label_dict\n",
        "\n",
        "def process_corpus(corpus_path, mode, vocab_dict=None, label_dict=None):\n",
        "    lines = open(corpus_path).readlines()\n",
        "    if not vocab_dict:\n",
        "        vocab_dict = {'UNK': 0}\n",
        "    if not label_dict:\n",
        "        label_dict = {'UNK': 0, 'Token': 1, 'None': 2}\n",
        "    corpus = []\n",
        "    sent_spans = []\n",
        "    raw_lines = []\n",
        "    for line in lines:\n",
        "      if len(line.strip()) < 3: \n",
        "        continue\n",
        "      word_ids, span_list, vocab_dict, label_dict = process_line(line, vocab_dict, label_dict, mode)\n",
        "      corpus.append(word_ids)\n",
        "      sent_spans.append(span_list)\n",
        "      raw_lines.append(line)\n",
        "    return corpus, sent_spans, vocab_dict, label_dict, raw_lines\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbhhKRL5246g"
      },
      "source": [
        "corpus_train, spans_train, vocab_dict, label_dict, train_lines = process_corpus('/content/hw3/trees/train.txt', 'train')\n",
        "corpus_valid, spans_valid, _, _, valid_lines = process_corpus('/content/hw3/trees/valid.txt', 'eval',\n",
        "                                                 vocab_dict=vocab_dict, label_dict=label_dict)\n",
        "corpus_test,  spans_test, _, _, test_lines = process_corpus('/content/hw3/trees/test.txt', 'eval',\n",
        "                                                 vocab_dict=vocab_dict, label_dict=label_dict)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHXGTFnPm3yV"
      },
      "source": [
        "inv_vocab_dict = np.array(list(vocab_dict.keys()))\n",
        "inv_label_dict = np.array(list(label_dict.keys()))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RZxYTjym00m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ded4fd27-7dbf-496c-d40c-4c9e7124dfa2"
      },
      "source": [
        "\n",
        "num_words = len(vocab_dict)\n",
        "num_labels = len(label_dict)\n",
        "\n",
        "print('Number of different words: {}'.format(num_words))\n",
        "print('Number of different labels: {}'.format(num_labels))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of different words: 8626\n",
            "Number of different labels: 147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGc5tgQtfunf"
      },
      "source": [
        "Let see how the data looks like, and compare with our output in below:\n",
        "```\n",
        "['how', 'long', 'will', 'it', 'take', 'to', 'drive', 'from', 'chicago', 'to', 'mississippi']\n",
        "how long will it take to drive from chicago to mississippi\t[IN:GET_ESTIMATED_DURATION how [SUB long [SUB will [SUB it [SUB take [SUB to [SUB [SL:METHOD_TRAVEL drive ] [SUB from [SUB [SL:SOURCE chicago ] [SUB to [SL:DESTINATION mississippi ] ] ] ] ] ] ] ] ] ] ]\n",
        "\n",
        "[[(0, 11), 3], [(0, 1), 1], [(1, 11), 4], [(1, 2), 1], [(2, 11), 4], [(2, 3), 1], [(3, 11), 4], [(3, 4), 1], [(4, 11), 4], [(4, 5), 1], [(5, 11), 4], [(5, 6), 1], [(6, 11), 4], [(6, 7), 5], [(7, 11), 4], [(7, 8), 1], [(8, 11), 4], [(8, 9), 6], [(9, 11), 4], [(9, 10), 1], [(10, 11), 7]]\n",
        "['will', 'it', 'take', 'shorter', 'to', 'get', 'to', 'the', 'white', 'house', 'by', 'bus', 'or', 'taxi', '?']\n",
        "will it take shorter to get to the white house by bus or taxi ?\t[IN:UNSUPPORTED_NAVIGATION will [SUB it [SUB take [SUB shorter [SUB to [SUB get [SUB to [SUB the [SUB white [SUB house [SUB by [SUB bus [SUB or [SUB taxi ? ] ] ] ] ] ] ] ] ] ] ] ] ] ]\n",
        "\n",
        "[[(0, 15), 8], [(0, 1), 1], [(1, 15), 4], [(1, 2), 1], [(2, 15), 4], [(2, 3), 1], [(3, 15), 4], [(3, 4), 1], [(4, 15), 4], [(4, 5), 1], [(5, 15), 4], [(5, 6), 1], [(6, 15), 4], [(6, 7), 1], [(7, 15), 4], [(7, 8), 1], [(8, 15), 4], [(8, 9), 1], [(9, 15), 4], [(9, 10), 1], [(10, 15), 4], [(10, 11), 1], [(11, 15), 4], [(11, 12), 1], [(12, 15), 4], [(12, 13), 1], [(13, 15), 4], [(13, 14), 1], [(14, 15), 1]]\n",
        "['will', 'i', 'make', 'it', 'to', 'the', 'beach', 'by', 'noon', 'if', 'i', 'leave', 'now']\n",
        "will i make it to the beach by noon if i leave now\t[IN:GET_ESTIMATED_ARRIVAL will [SUB i [SUB make [SUB it [SUB to [SUB [SL:DESTINATION--IN:GET_LOCATION--SL:CATEGORY_LOCATION the beach ] [SUB [SL:DATE_TIME_ARRIVAL by noon ] [SUB if [SUB i [SUB leave [SL:DATE_TIME_DEPARTURE now ] ] ] ] ] ] ] ] ] ] ]\n",
        "\n",
        "[[(0, 13), 9], [(0, 1), 1], [(1, 13), 4], [(1, 2), 1], [(2, 13), 4], [(2, 3), 1], [(3, 13), 4], [(3, 4), 1], [(4, 13), 4], [(4, 5), 1], [(5, 13), 4], [(5, 7), 10], [(5, 6), 1], [(6, 7), 1], [(7, 13), 4], [(7, 9), 11], [(7, 8), 1], [(8, 9), 1], [(9, 13), 4], [(9, 10), 1], [(10, 13), 4], [(10, 11), 1], [(11, 13), 4], [(11, 12), 1], [(12, 13), 12]]\n",
        "['when', 'should', 'i', 'leave', 'my', 'house', 'to', 'get', 'to', 'the', 'hamilton', 'mall', 'right', 'when', 'it', 'opens', 'on', 'saturday']\n",
        "when should i leave my house to get to the hamilton mall right when it opens on saturday\t[IN:GET_ESTIMATED_DEPARTURE when [SUB should [SUB i [SUB leave [SUB [SL:SOURCE--IN:GET_LOCATION_HOME [SL:CONTACT my ] house ] [SUB to [SUB get [SUB to [SUB [SL:DESTINATION--IN:GET_LOCATION--SL:POINT_ON_MAP the [SUB hamilton mall ] ] [SL:DATE_TIME_ARRIVAL right [SUB when [SUB it [SUB opens [SUB on saturday ] ] ] ] ] ] ] ] ] ] ] ] ] ]\n",
        "\n",
        "[[(0, 18), 13], [(0, 1), 1], [(1, 18), 4], [(1, 2), 1], [(2, 18), 4], [(2, 3), 1], [(3, 18), 4], [(3, 4), 1], [(4, 18), 4], [(4, 6), 14], [(4, 5), 15], [(5, 6), 1], [(6, 18), 4], [(6, 7), 1], [(7, 18), 4], [(7, 8), 1], [(8, 18), 4], [(8, 9), 1], [(9, 18), 4], [(9, 12), 16], [(9, 10), 1], [(10, 12), 4], [(10, 11), 1], [(11, 12), 1], [(12, 18), 11], [(12, 13), 1], [(13, 18), 4], [(13, 14), 1], [(14, 18), 4], [(14, 15), 1], [(15, 18), 4], [(15, 16), 1], [(16, 18), 4], [(16, 17), 1], [(17, 18), 1]]\n",
        "['i', 'need', 'to', 'know', 'if', 'there', \"'s\", 'a', 'lot', 'of', 'traffic', 'on', 'my', 'way', 'home']\n",
        "i need to know if there 's a lot of traffic on my way home\t[IN:GET_INFO_TRAFFIC i [SUB need [SUB to [SUB know [SUB if [SUB there [SUB 's [SUB a [SUB lot [SUB of [SUB traffic [SUB on [SUB my [SUB way [SL:DESTINATION--IN:GET_LOCATION_HOME home ] ] ] ] ] ] ] ] ] ] ] ] ] ] ]\n",
        "\n",
        "[[(0, 15), 17], [(0, 1), 1], [(1, 15), 4], [(1, 2), 1], [(2, 15), 4], [(2, 3), 1], [(3, 15), 4], [(3, 4), 1], [(4, 15), 4], [(4, 5), 1], [(5, 15), 4], [(5, 6), 1], [(6, 15), 4], [(6, 7), 1], [(7, 15), 4], [(7, 8), 1], [(8, 15), 4], [(8, 9), 1], [(9, 15), 4], [(9, 10), 1], [(10, 15), 4], [(10, 11), 1], [(11, 15), 4], [(11, 12), 1], [(12, 15), 4], [(12, 13), 1], [(13, 15), 4], [(13, 14), 1], [(14, 15), 18]]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTXUkgqxe3Rw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "008b4efc-3c82-41de-f524-ce7d0236c4c0"
      },
      "source": [
        "for i in range(5):\n",
        "  print([inv_vocab_dict[w] for w in corpus_train[i]])\n",
        "  print(train_lines[i])\n",
        "  print(spans_train[i])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['how', 'long', 'will', 'it', 'take', 'to', 'drive', 'from', 'chicago', 'to', 'mississippi']\n",
            "how long will it take to drive from chicago to mississippi\t[IN:GET_ESTIMATED_DURATION how [SUB long [SUB will [SUB it [SUB take [SUB to [SUB [SL:METHOD_TRAVEL drive ] [SUB from [SUB [SL:SOURCE chicago ] [SUB to [SL:DESTINATION mississippi ] ] ] ] ] ] ] ] ] ] ]\n",
            "\n",
            "[[(0, 11), 3], [(0, 1), 1], [(1, 11), 4], [(1, 2), 1], [(2, 11), 4], [(2, 3), 1], [(3, 11), 4], [(3, 4), 1], [(4, 11), 4], [(4, 5), 1], [(5, 11), 4], [(5, 6), 1], [(6, 11), 4], [(6, 7), 5], [(7, 11), 4], [(7, 8), 1], [(8, 11), 4], [(8, 9), 6], [(9, 11), 4], [(9, 10), 1], [(10, 11), 7]]\n",
            "['will', 'it', 'take', 'shorter', 'to', 'get', 'to', 'the', 'white', 'house', 'by', 'bus', 'or', 'taxi', '?']\n",
            "will it take shorter to get to the white house by bus or taxi ?\t[IN:UNSUPPORTED_NAVIGATION will [SUB it [SUB take [SUB shorter [SUB to [SUB get [SUB to [SUB the [SUB white [SUB house [SUB by [SUB bus [SUB or [SUB taxi ? ] ] ] ] ] ] ] ] ] ] ] ] ] ]\n",
            "\n",
            "[[(0, 15), 8], [(0, 1), 1], [(1, 15), 4], [(1, 2), 1], [(2, 15), 4], [(2, 3), 1], [(3, 15), 4], [(3, 4), 1], [(4, 15), 4], [(4, 5), 1], [(5, 15), 4], [(5, 6), 1], [(6, 15), 4], [(6, 7), 1], [(7, 15), 4], [(7, 8), 1], [(8, 15), 4], [(8, 9), 1], [(9, 15), 4], [(9, 10), 1], [(10, 15), 4], [(10, 11), 1], [(11, 15), 4], [(11, 12), 1], [(12, 15), 4], [(12, 13), 1], [(13, 15), 4], [(13, 14), 1], [(14, 15), 1]]\n",
            "['will', 'i', 'make', 'it', 'to', 'the', 'beach', 'by', 'noon', 'if', 'i', 'leave', 'now']\n",
            "will i make it to the beach by noon if i leave now\t[IN:GET_ESTIMATED_ARRIVAL will [SUB i [SUB make [SUB it [SUB to [SUB [SL:DESTINATION--IN:GET_LOCATION--SL:CATEGORY_LOCATION the beach ] [SUB [SL:DATE_TIME_ARRIVAL by noon ] [SUB if [SUB i [SUB leave [SL:DATE_TIME_DEPARTURE now ] ] ] ] ] ] ] ] ] ] ]\n",
            "\n",
            "[[(0, 13), 9], [(0, 1), 1], [(1, 13), 4], [(1, 2), 1], [(2, 13), 4], [(2, 3), 1], [(3, 13), 4], [(3, 4), 1], [(4, 13), 4], [(4, 5), 1], [(5, 13), 4], [(5, 7), 10], [(5, 6), 1], [(6, 7), 1], [(7, 13), 4], [(7, 9), 11], [(7, 8), 1], [(8, 9), 1], [(9, 13), 4], [(9, 10), 1], [(10, 13), 4], [(10, 11), 1], [(11, 13), 4], [(11, 12), 1], [(12, 13), 12]]\n",
            "['when', 'should', 'i', 'leave', 'my', 'house', 'to', 'get', 'to', 'the', 'hamilton', 'mall', 'right', 'when', 'it', 'opens', 'on', 'saturday']\n",
            "when should i leave my house to get to the hamilton mall right when it opens on saturday\t[IN:GET_ESTIMATED_DEPARTURE when [SUB should [SUB i [SUB leave [SUB [SL:SOURCE--IN:GET_LOCATION_HOME [SL:CONTACT my ] house ] [SUB to [SUB get [SUB to [SUB [SL:DESTINATION--IN:GET_LOCATION--SL:POINT_ON_MAP the [SUB hamilton mall ] ] [SL:DATE_TIME_ARRIVAL right [SUB when [SUB it [SUB opens [SUB on saturday ] ] ] ] ] ] ] ] ] ] ] ] ] ]\n",
            "\n",
            "[[(0, 18), 13], [(0, 1), 1], [(1, 18), 4], [(1, 2), 1], [(2, 18), 4], [(2, 3), 1], [(3, 18), 4], [(3, 4), 1], [(4, 18), 4], [(4, 6), 14], [(4, 5), 15], [(5, 6), 1], [(6, 18), 4], [(6, 7), 1], [(7, 18), 4], [(7, 8), 1], [(8, 18), 4], [(8, 9), 1], [(9, 18), 4], [(9, 12), 16], [(9, 10), 1], [(10, 12), 4], [(10, 11), 1], [(11, 12), 1], [(12, 18), 11], [(12, 13), 1], [(13, 18), 4], [(13, 14), 1], [(14, 18), 4], [(14, 15), 1], [(15, 18), 4], [(15, 16), 1], [(16, 18), 4], [(16, 17), 1], [(17, 18), 1]]\n",
            "['i', 'need', 'to', 'know', 'if', 'there', \"'s\", 'a', 'lot', 'of', 'traffic', 'on', 'my', 'way', 'home']\n",
            "i need to know if there 's a lot of traffic on my way home\t[IN:GET_INFO_TRAFFIC i [SUB need [SUB to [SUB know [SUB if [SUB there [SUB 's [SUB a [SUB lot [SUB of [SUB traffic [SUB on [SUB my [SUB way [SL:DESTINATION--IN:GET_LOCATION_HOME home ] ] ] ] ] ] ] ] ] ] ] ] ] ] ]\n",
            "\n",
            "[[(0, 15), 17], [(0, 1), 1], [(1, 15), 4], [(1, 2), 1], [(2, 15), 4], [(2, 3), 1], [(3, 15), 4], [(3, 4), 1], [(4, 15), 4], [(4, 5), 1], [(5, 15), 4], [(5, 6), 1], [(6, 15), 4], [(6, 7), 1], [(7, 15), 4], [(7, 8), 1], [(8, 15), 4], [(8, 9), 1], [(9, 15), 4], [(9, 10), 1], [(10, 15), 4], [(10, 11), 1], [(11, 15), 4], [(11, 12), 1], [(12, 15), 4], [(12, 13), 1], [(13, 15), 4], [(13, 14), 1], [(14, 15), 18]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j_0UKnEHN4R"
      },
      "source": [
        "### **Defining the Neural Network**\n",
        "\n",
        "#### **Sentence Encoding**\n",
        "\n",
        "We use a Bi-directional LSTM for sentence encoding. We build a sentence encoder with a embedding layer and a Bi-directional LSTM layer:\n",
        "\n",
        "- Input: \n",
        " - word indices: `[batch_size, sentence_length]`\n",
        "- Output: \n",
        "  - word embeddings: `[batch_size, sentence_length, hidden_size]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTq0SpbfHN4S"
      },
      "source": [
        "class SentEnc(nn.Module):\n",
        "    def __init__(self, num_words, num_layers, hidden_size, dropout=0):\n",
        "        super(SentEnc, self).__init__()\n",
        "\n",
        "        # Hidden dimensions\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Number of hidden layers\n",
        "        self.num_layers = num_layers\n",
        "    \n",
        "        \n",
        "        # --------- Your code --------- #\n",
        "        # Construct your lstm module here (single line):\n",
        "\n",
        "        self.lstm = nn.LSTM(num_words, \n",
        "                            hidden_size, \n",
        "                            num_layers, \n",
        "                            dropout = dropout, \n",
        "                            bidirectional = True)\n",
        "\n",
        "        # --------- Your code ends --------- #\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # --------- Your code --------- #\n",
        "        # Initialize hidden state with zeros\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).requires_grad_()\n",
        "\n",
        "        # Initialize cell state\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).requires_grad_()\n",
        "\n",
        "        # embed = self.embedding(x)\n",
        "\n",
        "        outputs, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
        "        \n",
        "\n",
        "        # --------- Your code ends --------- #\n",
        "        return outputs"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em12BpkGHN4X"
      },
      "source": [
        "### **Span Encodings**\n",
        "\n",
        "Given the LSTM outputs, we generate the span embeddings with the span indices.\n",
        "\n",
        "We generate a span embedding by concatenating the word embeddings of the first and last words of a span. For example, if a span starts from the i-th word and ends at the j-th word, our span embedding would be\n",
        "\n",
        "$$[h_i^T; h_j^T]^T$$\n",
        "\n",
        "where $h_i$ stands for the Bi-LSTM output of the $i^{th}$ word.\n",
        "\n",
        "In Pytorch, Given the hidden states $h[0], h[1], ..., h[n]$, where\n",
        "```\n",
        "h[i].size() = [1, k]\n",
        "```\n",
        "the embedding of span (i, j) is\n",
        "```\n",
        "span_ij = torch.cat([h[i], h[j]], dim=1)\n",
        "span_ij.size() = [1, 2 * k]\n",
        "```\n",
        "Please complete the following function for generating span embeddings.\n",
        "\n",
        "- Input: \n",
        " - word embeddings: `[sentence_length, hidden_size]` \n",
        " - span indices: `[num_span, 2]`\n",
        "- Output: \n",
        " - span embeddings `[num_span, hidden_size * 2]`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afGE-9pZHN4Z"
      },
      "source": [
        "def get_span_embeddings(word_embeddings, span_indices):\n",
        "    # --------- Your code --------- #\n",
        "    for i in range(len(word_embeddings)):\n",
        "      for j in range()\n",
        "\n",
        "    # --------- Your code ends --------- #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3zP3fhqSFuh",
        "outputId": "f933dd07-9e99-4336-d06d-23d5fa51ddcd"
      },
      "source": [
        "sentence_length = 10\n",
        "hidden_size = 5\n",
        "span_indices = [3, 2]\n",
        "a = torch.rand(sentence_length, hidden_size)\n",
        "a[1].size()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR02v0-8ScMb",
        "outputId": "c082d3fa-e673-4d72-91d4-3b217592596c"
      },
      "source": [
        "a[1].size() == [1, 5]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGWEtK8pSHvV"
      },
      "source": [
        "torch.empty(2, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmDK0xKfHN4g"
      },
      "source": [
        "### **Tag Prediction**\n",
        "\n",
        "We build a Classifier that puts the neural models together. The classifier takes word and span indices as inputs, and predict span labels by calculating word embeddings, span embeddings, and label logits. we will predict the tag of the spans with a linear classifier.\n",
        "\n",
        "- Inputs: \n",
        " - word indices: `[batch_size, num_words]`\n",
        "- Outputs: \n",
        " - span predictions: `[num_spans, num_labels]`\n",
        "\n",
        "Please implement the forward function following 4 steps:\n",
        "1. Generate the word embeddings by processing the input sentences with the LSTM sentence encoder.\n",
        "2. Apply dropout on word embeddings.\n",
        "3. Calculate span embeddings with function get_span_embeddings().\n",
        "4. Calculate label logits with the linear layer defined as follows.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtWAptvBHN4i"
      },
      "source": [
        "##CHANGED BY ME\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_words, num_labels, num_layers, hidden_size, dropout=0):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.sent_enc = SentEnc(num_words, num_layers, hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(4 * hidden_size, num_labels)\n",
        "    \n",
        "    def forward(self, x, span_indices):\n",
        "        # --------- Your code --------- #\n",
        "        output = self.sent_enc(x)\n",
        "        output = self.dropout(output)\n",
        "        span_embeds = get_span_embeddings(output, span_indices)\n",
        "        logits = self.linear(span_embeds)\n",
        "        \n",
        "        # --------- Your code ends --------- #\n",
        "        return logits"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUMXzQPS3Xh2"
      },
      "source": [
        "#For decoding, we add some random spans and label them as \"None\"\n",
        "def add_none_span(word_list, span_list, label_dict, all=False):\n",
        "    num_words = len(word_list)\n",
        "    num_labeled_span = len(span_list)\n",
        "    labeled_span_set = set([span for span, label in span_list])\n",
        "    none_spans = []\n",
        "    for i in range(num_words):\n",
        "        for j in range(i + 1, num_words):\n",
        "            if (i, j) not in labeled_span_set:\n",
        "                none_spans.append([(i, j), label_dict['None']])\n",
        "    if not all:\n",
        "        k = min(num_labeled_span, len(none_spans))\n",
        "        sampled_none_spans = random.sample(none_spans, k)\n",
        "    else:\n",
        "        sampled_none_spans = none_spans\n",
        "    return span_list + sampled_none_spans"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0VYVg6RHN4o"
      },
      "source": [
        "### **Training Loop**\n",
        "\n",
        "With all neural models already defined, we are implementing the training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B82dn5UhHN4p"
      },
      "source": [
        "print('Using device: {}'.format(device))\n",
        "\n",
        "\n",
        "# just remeber you can tune these hyper-parameters!\n",
        "batch_size = 1\n",
        "num_layers = 2\n",
        "hidden_size = 200\n",
        "lr = 0.05\n",
        "num_epochs = 3 #Be aware of over-fitting!\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "dropout = 0.25\n",
        "\n",
        "classifier = Classifier(num_words, num_labels, num_layers, hidden_size, dropout)\n",
        "optimizer = optim.SGD(classifier.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "classifier = classifier.to(device)\n",
        "classifier.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    classifier.train()\n",
        "    for i in range(len(corpus_train)):\n",
        "\n",
        "        if i % 10000 == 0:\n",
        "            print('Epoch {} Batch {}'.format(epoch, i))\n",
        "        \n",
        "        cur_spans = add_none_span(corpus_train[i], spans_train[i], label_dict)\n",
        "        \n",
        "        sent_inputs  = torch.Tensor([corpus_train[i]]).long().to(device)\n",
        "        span_indices = torch.Tensor([x[0] for x in cur_spans]).long().to(device)\n",
        "        span_labels  = torch.Tensor([x[1] for x in cur_spans]).long().to(device)\n",
        "        \n",
        "        # --------- Your code --------- #\n",
        "        \n",
        "\n",
        "\n",
        "        # --------- Your code ends --------- #\n",
        "    print('Epoch {}, train loss={}'.format(epoch, total_loss / len(corpus_train)))\n",
        "\n",
        "    total_loss = 0\n",
        "    classifier.eval()\n",
        "    for i in range(len(corpus_valid)):\n",
        "        #if i % 10000 == 0:\n",
        "        #    print('Epoch {} Batch {}'.format(epoch, i))\n",
        "        cur_spans = add_none_span(corpus_valid[i], spans_valid[i], label_dict)\n",
        "        \n",
        "        sent_inputs  = torch.Tensor([corpus_valid[i]]).long().to(device)\n",
        "        span_indices = torch.Tensor([x[0] for x in cur_spans]).long().to(device)\n",
        "        span_labels  = torch.Tensor([x[1] for x in cur_spans]).long().to(device)\n",
        "        \n",
        "        # --------- Your code --------- #\n",
        "\n",
        "\n",
        "\n",
        "        # --------- Your code ends --------- #\n",
        "    print('Epoch {}, valid loss={}'.format(epoch, total_loss / len(corpus_valid)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4ODDfXKHN4s"
      },
      "source": [
        "### **Evaluation**\n",
        "\n",
        "After training the model, we evaluate the classification results.  \n",
        "What we will do is that we treat a tree strcture as a bag of spans (a list of span indices), and then compute F-1 score.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH5bRW6UHN4t"
      },
      "source": [
        "from itertools import zip_longest\n",
        "from typing import Counter, Dict, Optional\n",
        "import numpy as np\n",
        "\n",
        "class Calculator:\n",
        "    def __init__(self, strict = False) -> None:\n",
        "        self.TP = 0\n",
        "        self.gold_P = 0\n",
        "        self.pred_P = 0      \n",
        "        self.exact_match = []\n",
        "        self.tree_match = []\n",
        "        self.well_form = []\n",
        "        self.strict = strict\n",
        "\n",
        "    def get_metrics(self):\n",
        "        precision = (self.TP / self.pred_P) if self.pred_P else 0\n",
        "        recall = (self.TP / self.gold_P) if self.gold_P else 0\n",
        "        f1 = (2.0 * precision * recall / (precision + recall)) if (precision + recall) else 0\n",
        "     \n",
        "        return {\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"f1\": f1,\n",
        "            \"exact_match\": np.mean(self.exact_match),\n",
        "            \"well_form\": np.mean(self.well_form),\n",
        "            \"tree_match\":  np.mean(self.tree_match),\n",
        "            \"num_examples\": len(self.exact_match)\n",
        "        }\n",
        "    \n",
        "    def is_well_formed(self, spans):   \n",
        "        for s1 in spans: \n",
        "          for s2 in spans:\n",
        "              if s1[0] < s2[0] and s2[0] < s1[1] and s1[1] < s2[1]:\n",
        "                    return False\n",
        "        return True\n",
        "\n",
        "    def add_instance_span(self, gold_spans, pred_spans):\n",
        "        self.gold_P += len(gold_spans)\n",
        "        self.pred_P += len(pred_spans)\n",
        "        self.TP += len(set(gold_spans) & set(pred_spans))\n",
        "        self.exact_match.append(int(set(gold_spans) == set(pred_spans)))\n",
        "        gold_spans = [s[0] for s in gold_spans]\n",
        "        pred_spans = [s[0] for s in pred_spans]\n",
        "        self.tree_match.append(int(set(gold_spans) == set(pred_spans)))\n",
        "        well_formed = self.is_well_formed(pred_spans)\n",
        "        self.well_form.append(int(well_formed))\n",
        "\n",
        "    def add_instance_tree(self, gold_tree, pred_tree):\n",
        "        node_info_gold = self._get_node_info(gold_tree)\n",
        "        self.gold_P += len(node_info_gold)\n",
        "        node_info_pred = self._get_node_info(pred_tree)\n",
        "        self.pred_P += len(node_info_pred)\n",
        "        self.TP += len(node_info_gold & node_info_pred)\n",
        "        self.exact_match.append(int(node_info_gold.keys() == node_info_pred.keys()))\n",
        "        self.well_form.append(1) #we assume the decoded tree is indeed a tree :)\n",
        "        node_info_gold = {k[1] for k,v in node_info_gold.items()}\n",
        "        node_info_pred = {k[1] for k,v in node_info_pred.items()}\n",
        "        self.tree_match.append(int(node_info_gold==node_info_pred))\n",
        "        \n",
        "    def _get_node_info(self, tree) -> Counter:\n",
        "        nodes = tree.root.list_nonterminals()\n",
        "        node_info: Counter = Counter()\n",
        "        for node in nodes:\n",
        "            if node.label != 'Token':\n",
        "              span = self._get_span(node)\n",
        "              node_info[(node.label, self._get_span(node))] += 1 \n",
        "\n",
        "        return node_info\n",
        "\n",
        "    def _get_span(self, node):\n",
        "        return node.get_flat_str_spans(\n",
        "        ) if self.strict else node.get_token_span()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mamC7tgxD1r5"
      },
      "source": [
        "classifier.eval()\n",
        "parta_calc = Calculator(strict=False)\n",
        "pred_bag_spans = []\n",
        "gold_bag_spans = []\n",
        "for (tokens, spans, line) in zip(corpus_test,spans_test,test_lines):   \n",
        "    #We only test non-Token labels\n",
        "    spans = [tuple(x) for x in spans if x[1] != 1]\n",
        "\n",
        "    if len(spans) <= 1 or len(line.strip()) < 3: \n",
        "      continue\n",
        "\n",
        "    all_spans = [(i,j) for i in range(len(tokens)) \n",
        "                        for j in range(i + 1, len(tokens) + 1)]\n",
        "\n",
        "    input  = torch.Tensor([tokens]).long().to(device)\n",
        "    logits = classifier(input, torch.Tensor(all_spans).long().to(device))\n",
        "\n",
        "    pred_spans = []\n",
        "    for i, span in enumerate(all_spans):\n",
        "        label_idx = torch.argmax(logits[i]).item()\n",
        "        if label_idx != 2 and label_idx != 1:\n",
        "          pred_spans.append((span,label_idx))\n",
        "    \n",
        "    parta_calc.add_instance_span(spans, pred_spans)\n",
        "    pred_bag_spans.append(pred_spans)\n",
        "    gold_bag_spans.append(spans)\n",
        " \n",
        "print(parta_calc.get_metrics())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lasnfaK4qTfU"
      },
      "source": [
        "## **PARTB** (Only for 6.864 students)\n",
        "The remaining will be **PartB** for **HW3-Trees**.  \n",
        "In PartB, we will decode a tree based on the classifier trained on part A.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlF7r2WOylDH"
      },
      "source": [
        "### **CKY**  \n",
        "You will be implementing the following simple CYK recursion:  \n",
        "```best_score[i,j]=max_k {best_score[i,k]+best_score[k,j]} + max_l {span_dict[(i,j)][l]}```      \n",
        "where `l` is the label of the current span `(i,j)`, and `k` is the splitting point\n",
        "\n",
        "Note that this is a simpler recursion than the full CKY algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHPVa39Fqhhs"
      },
      "source": [
        "from torch.nn.functional import log_softmax\n",
        "EPS = 1e-6\n",
        "dp_results = []\n",
        "classifier.eval()\n",
        "for kk,(line,spans,tokens) in enumerate(zip(test_lines,spans_test,corpus_test)):\n",
        "    spans = [tuple(x) for x in spans if  x[1] != 1]\n",
        "    \n",
        "    if len(spans) <= 1 or len(line.strip()) < 3: \n",
        "      continue\n",
        "    \n",
        "    sent_inputs  = torch.Tensor([tokens]).long().to(device)\n",
        "    \n",
        "    all_spans = [(i,j) for i in range(len(tokens)) \n",
        "                         for j in range(i + 1, len(tokens) + 1)]\n",
        "    \n",
        "    logits = classifier(sent_inputs, torch.Tensor(all_spans).long().to(device))\n",
        "    logprobs = log_softmax(logits, dim = -1)\n",
        "    # span dict will map each span (l,r) to its predicted distribution of labels\n",
        "    span_dict = {}\n",
        "    for i, s in enumerate(all_spans): \n",
        "      span_dict[s]  = logprobs[i] \n",
        "  \n",
        "    TOKEN_ID, NULL_ID = 1, 2\n",
        "    best_score, best_split, best_label = {}, {}, {} # we will do dynamic programming to decode a binary tree out of our predictions\n",
        "    # Think: why do we first iterate the length of the span?\n",
        "    for ll in range(1, len(tokens) + 1): # length of the span\n",
        "        for i in range(0, len(tokens)-ll+1): # start of the span\n",
        "            j = i + ll\n",
        "            cur_span = (i, j)\n",
        "            if j == i + 1:\n",
        "                span_dict[cur_span][NULL_ID]  = -1/EPS\n",
        "                # --------- Your code --------- #\n",
        "                #use span_dict[cur_span] to update best_label and best_score, be careful, it could either be a TOKEN or something else              \n",
        "\n",
        "                \n",
        "                # --------- Your code ends --------- #\n",
        "                best_split[cur_span] = None\n",
        "            else:\n",
        "                span_dict[cur_span][NULL_ID]  = -1/EPS # we will never decode a NULL sub-tree\n",
        "                span_dict[cur_span][TOKEN_ID] = -1/EPS # we will never decode a NULL sub-tree\n",
        "                # --------- Your code --------- #\n",
        "                #try to give the values for best_score/label/split[cur_span]\n",
        "\n",
        "\n",
        "\n",
        "                # --------- Your code ends --------- #\n",
        "            #print(cur_span, best_score[cur_span], best_label[cur_span])\n",
        "    dp_results.append((best_score, best_split, best_label))\n",
        "print(len(dp_results))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp7gnX87QFog"
      },
      "source": [
        "### **Tree Construction**\n",
        "In this section, we will construct a tree using the DP results.  \n",
        "Before start doing it, please get yourself a little familiar with the span_tree.py."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpKRpZEiSNF1"
      },
      "source": [
        "import sys\n",
        "def get_nodetype(label):\n",
        "    if label.startswith(PREFIX_INTENT):\n",
        "        node = Intent(label)\n",
        "    elif label.startswith(PREFIX_SLOT):\n",
        "        node = Slot(label)\n",
        "    elif label.startswith(PREFIX_SUBTREE):\n",
        "        node = SubTree(label)\n",
        "    else:\n",
        "        print('something wrong with the label!!!', label)\n",
        "        sys.error()\n",
        "    return node\n",
        "\n",
        "def dfs_build(l, r, best_label, best_split):\n",
        "    if l + 1 == r:\n",
        "        la = best_label[(l,r)]\n",
        "        if la == 1:\n",
        "            return Token(surface_tokens[l], l)\n",
        "        else:\n",
        "            node = get_nodetype(inv_label_dict[la])\n",
        "            node.children = [Token(surface_tokens[l], l)]\n",
        "            node.children[0].parent = node\n",
        "            return node\n",
        "\n",
        "    label = inv_label_dict[best_label[(l, r)]]\n",
        "    node = get_nodetype(label)\n",
        "    \n",
        "    #--- your code --- #\n",
        "    #hint: use best_split! and recursion to assign node.children here\n",
        "\n",
        "\n",
        "    #--- your code ends --- #\n",
        "\n",
        "    for c in node.children:\n",
        "        c.parent = node\n",
        "    \n",
        "    return node\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LvUbHYcJN9G"
      },
      "source": [
        "pred_trees = []\n",
        "gold_trees = []\n",
        "partb_calc = Calculator(strict=False)\n",
        "k = 0\n",
        "for i,(line,spans,tokens) in enumerate(zip(test_lines,spans_test,corpus_test)):\n",
        "    surface_tokens, str_ref_tree = line.strip().split('\\t')\n",
        "    surface_tokens = surface_tokens.split()\n",
        "    spans = [tuple(x) for x in spans if x[1] != 1]\n",
        "\n",
        "    if len(spans) <= 1 or len(line.strip()) < 3: \n",
        "      continue\n",
        "\n",
        "    best_score, best_split, best_label = dp_results[k]\n",
        "    k+=1\n",
        "    root = Root()\n",
        "    root.children = [dfs_build(0, len(tokens), best_label, best_split)]\n",
        "    root.children[0].parent = root\n",
        "    tree = Tree('IN:GET_EVENT placeholder') #the string here is just a placeholder\n",
        "    tree.root = root\n",
        "    if k < 10: #use this info for debugging! Does your tree make sense?\n",
        "        print(k, line.strip())\n",
        "        print('REF:', str_ref_tree)\n",
        "        print('DEC:', str(tree))\n",
        "        print()\n",
        "    \"\"\" here's some decoding examples we get\n",
        "      1 whats there to do this weekend\t[IN:GET_EVENT whats [SUB there [SUB to [SUB do [SL:DATE_TIME this weekend ] ] ] ] ]\n",
        "      REF: [IN:GET_EVENT whats [SUB there [SUB to [SUB do [SL:DATE_TIME this weekend ] ] ] ] ]\n",
        "      DEC: [IN:GET_EVENT whats [SUB there [SUB to [SUB do [SL:DATE_TIME this weekend ] ] ] ] ]\n",
        "\n",
        "      2 what is a good restaurant for tex mex in austin\t[IN:UNSUPPORTED what [SUB is [SUB a [SUB good [SUB restaurant [SUB for [SUB tex [SUB mex [SUB in austin ] ] ] ] ] ] ] ] ]\n",
        "      REF: [IN:UNSUPPORTED what [SUB is [SUB a [SUB good [SUB restaurant [SUB for [SUB tex [SUB mex [SUB in austin ] ] ] ] ] ] ] ] ]\n",
        "      DEC: [IN:UNSUPPORTED what [SUB is [SUB a [SUB good [SUB restaurant [SUB for [SUB tex [SUB mex [SUB in austin ] ] ] ] ] ] ] ] ]\n",
        "\n",
        "      3 where can i see the fireworks tonight\t[IN:GET_EVENT where [SUB can [SUB i [SUB see [SUB [SL:CATEGORY_EVENT the fireworks ] [SL:DATE_TIME tonight ] ] ] ] ] ]\n",
        "      REF: [IN:GET_EVENT where [SUB can [SUB i [SUB see [SUB [SL:CATEGORY_EVENT the fireworks ] [SL:DATE_TIME tonight ] ] ] ] ] ]\n",
        "      DEC: [IN:GET_EVENT where [SUB can [SUB i [SUB see [SUB the [SUB fireworks [SL:DATE_TIME tonight ] ] ] ] ] ] ]\n",
        "    \"\"\"\n",
        "    partb_calc.add_instance_tree(Tree(str_ref_tree), tree)\n",
        "    pred_trees.append(tree)\n",
        "    gold_trees.append(Tree(str_ref_tree))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io91TrAERMhB"
      },
      "source": [
        "print(partb_calc.get_metrics())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvT7-lGzbT2W"
      },
      "source": [
        "\n",
        "Recommended Reading (not required, just for interested students):  \n",
        "https://arxiv.org/pdf/1810.07942.pdf  \n",
        "https://www.aclweb.org/anthology/D16-1257/  \n",
        "https://arxiv.org/abs/1412.7449  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSvpOal-CzHm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}